# -*- coding: utf-8 -*-
"""ML_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z6ZjArgeLl7_UAMBJhS3rVpY8lwIUBeA
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score
from sklearn.model_selection import GridSearchCV

# Data Exploration

# Load dataset
df = pd.read_csv('diabetes_indicators.csv')

# Display dataset info
print(df.info())

# Summary statistics
print(df.describe())

# Preprocessing

# Check null values
print(df.isnull().sum())

#checking unique values in different variables
unique_values = {}
for col in df.columns:
    unique_values[col] = df[col].value_counts().shape[0]

pd.DataFrame(unique_values, index=['unique value count']).transpose()

# Check and drop duplicats
df.duplicated().sum()
df.drop_duplicates(inplace = True)
df.duplicated().sum()

#check for NAs
print(df.isnull().sum())
df = df.dropna()

#Transform the data to integer

df["Diabetes_012"] = df["Diabetes_012"].astype(int)
df["HighBP"] = df["HighBP"].astype(int)
df["HighChol"] = df["HighChol"].astype(int)
df["CholCheck"] = df["CholCheck"].astype(int)
df["BMI"] = df["BMI"].astype(int)
df["Smoker"] = df["Smoker"].astype(int)
df["Stroke"] = df["Stroke"].astype(int)
df["HeartDiseaseorAttack"] = df["HeartDiseaseorAttack"].astype(int)
df["PhysActivity"] = df["PhysActivity"].astype(int)
df["Fruits"] = df["Fruits"].astype(int)
df["Veggies"] = df["Veggies"].astype(int)
df["HvyAlcoholConsump"] = df["HvyAlcoholConsump"].astype(int)
df["AnyHealthcare"] = df["AnyHealthcare"].astype(int)
df["NoDocbcCost"] = df["NoDocbcCost"].astype(int)
df["GenHlth"] = df["GenHlth"].astype(int)
df["MentHlth"] = df["MentHlth"].astype(int)
df["PhysHlth"] = df["PhysHlth"].astype(int)
df["DiffWalk"] = df["DiffWalk"].astype(int)
df["Sex"] = df["Sex"].astype(int)
df["Age"] = df["Age"].astype(int)
df["Education"] = df["Education"].astype(int)
df["Income"] = df["Income"].astype(int)

# Check for Outliers
plt.figure(figsize=(15, 15))
for i, col in enumerate(['BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']):
    plt.subplot(4, 2, i+1)
    sns.boxplot(x=col, data=df, palette='Set2')
plt.tight_layout()
plt.show()

# EDA

# Outlier detection (boxplot for visualizing)
plt.figure(figsize=(20, 8))
sns.boxplot(data=df)
plt.title('Boxplot for Outlier Detection')
plt.show()

# Histograms for numeric columns
df.hist(figsize = (20,20))
plt.show()

# Correlation analysis using Heatmap


plt.figure(figsize = (20,10))
sns.heatmap(df.corr(),annot=True , cmap ='coolwarm' )
plt.title("correlation Heatmap")

# Binary feature columns to analyze
cols = [ 'HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Veggies',
        'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'DiffWalk']
# Function to create a pivot table for plotting
def create_plot_pivot(df, x_column):
    """Create pivot table for Diabetes_012 vs another feature"""
    temp = df.groupby([x_column, 'Diabetes_012']).size().reset_index(name='count')
    pivot = temp.pivot(index=x_column, columns='Diabetes_012', values='count')
    return pivot

# Create stacked bar plots for each feature
fig, ax = plt.subplots(3, 4, figsize=(20, 20))
axes = ax.ravel()

for i, col in enumerate(cols):
    pivot_table = create_plot_pivot(df, col)
    pivot_table.plot(kind='bar', stacked=True, ax=axes[i])
    axes[i].set_xlabel(col)
    axes[i].set_ylabel('Count')
    axes[i].legend(title='Diabetes')

plt.tight_layout()
plt.show()

# Feature Selections

df.drop('Diabetes_012', axis=1).corrwith(df.Diabetes_012).plot(kind='bar', grid=True, figsize=(20, 8)
, title="Correlation with Diabetes_012",color="Purple");

# Splitting data for the training

from sklearn.model_selection import train_test_split
X = df.drop('Diabetes_012', axis = 1)
y = df['Diabetes_012']
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.20)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import precision_score, recall_score
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import confusion_matrix

# Data Scalling
from sklearn.preprocessing import StandardScaler
scalar = StandardScaler()
X_train = scalar.fit_transform(X_train)
X_test = scalar.fit_transform(X_test)

# Modeling

from sklearn.linear_model import LogisticRegression
log_reg = LogisticRegression(C=1, penalty='l2', solver='liblinear', max_iter=200)
log_reg.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns

def predict_and_plot(model, inputs, targets, name=''):
    preds = model.predict(inputs)
    accuracy = accuracy_score(targets, preds)
    print("Accuracy: {:.2f}%".format(accuracy * 100))

    cf = confusion_matrix(targets, preds, normalize='true')
    plt.figure()
    sns.heatmap(cf, annot=True)
    plt.xlabel('Prediction')
    plt.ylabel('Target')
    plt.title('{} Confusion Matrix'.format(name))

    return preds

# Predict and plot on the training data
train_preds = predict_and_plot(log_reg, X_train, y_train, 'Train')

# Predict and plot on the validation data
val_preds = predict_and_plot(log_reg, X_test, y_test, 'Validation')

# Random Forest
from sklearn.ensemble import RandomForestClassifier
model_2 = RandomForestClassifier(n_jobs =-1, random_state = 42)
model_2.fit(X_train,y_train)

# make predictions on test set
y_pred=model_2.predict(X_test)

print('Training set accuracy: {:.4f}'.format(model_2.score(X_train, y_train)))

print('Test set accuracy: {:.4f}'.format(model_2.score(X_test, y_test)))

# descion tree
from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier( max_depth= 12)
dt.fit(X_train , y_train)

# make predictions on test set
train_accuracy = dt.score(X_train, y_train)
test_accuracy = dt.score(X_test, y_test)

print("Training Accuracy:", train_accuracy)
print("Test Accuracy:", test_accuracy)

# KNN
knn = KNeighborsClassifier(n_neighbors=6)
knn.fit(X_train, y_train)

y_pred=knn.predict(X_test)
print('Training set score: {:.4f}'.format(knn.score(X_train, y_train)))
print('Test set score: {:.4f}'.format(knn.score(X_test, y_test)))

# calculating and plotting the confusion matrix

confusion = confusion_matrix(y_test, y_pred)

# plot
plt.figure(figsize=(4, 3))
sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix: KNN')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.tight_layout()
plt.show()

# Random Forest
rf = RandomForestClassifier(max_depth=12, n_estimators=10, random_state=42)
rf.fit(X_train, y_train)

# make predictions on test set
y_pred=rf.predict(X_test)

print('Training set score: {:.4f}'.format(rf.score(X_train, y_train)))
print('Test set score: {:.4f}'.format(rf.score(X_test, y_test)))


# calculating and plotting the confusion matrix

cm1 = confusion_matrix(y_test, y_pred)

disp = ConfusionMatrixDisplay(confusion_matrix=cm1)
disp.plot(cmap='Blues')
plt.title('Confusion Matrix: Random Forest')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.tight_layout()
plt.show()

#XGBoost

from xgboost import XGBClassifier
xg = XGBClassifier(eval_metric= 'error', learning_rate= 0.1)
xg.fit(X_train , y_train)
y_pred=xg.predict(X_test)

print('Training set score: {:.4f}'.format(xg.score(X_train, y_train)))
print('Test set score: {:.4f}'.format(xg.score(X_test, y_test)))

# calculating and plotting the confusion matrix
cm1 = confusion_matrix(y_test, y_pred)

disp = ConfusionMatrixDisplay(confusion_matrix=cm1)
disp.plot(cmap='Blues')
plt.title('Confusion Matrix: XGBoost')
plt.xlabel('Predicted')
plt.ylabel(True)
plt.tight_layout()
plt.show()

import joblib

joblib.dump(xg, "xgboost_model.pkl")
joblib.dump(scalar, "scaler.pkl")

#validation

from sklearn.metrics import precision_score, recall_score

precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')

print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")